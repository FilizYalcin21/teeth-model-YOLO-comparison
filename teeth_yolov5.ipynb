{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNveqeA1KXGy"
      },
      "source": [
        "# Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTvDNSILZoN9",
        "outputId": "f62e47cc-d7cc-46b0-858b-cb5e53061c0c"
      },
      "source": [
        "#clone YOLOv5 and\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16656, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 16656 (delta 1), reused 5 (delta 0), pack-reused 16649\u001b[K\n",
            "Receiving objects: 100% (16656/16656), 15.07 MiB | 12.04 MiB/s, done.\n",
            "Resolving deltas: 100% (11443/11443), done.\n",
            "/content/yolov5\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetup complete. Using torch 2.3.0+cu121 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset"
      ],
      "metadata": {
        "id": "d0BZRqNeJwMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a directory for the dataset\n",
        "!mkdir /content/datasets"
      ],
      "metadata": {
        "id": "hwf6SF9i5M2I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset zip file\n",
        "!unzip /content/teeth.zip -d /content/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1y_22Kg5SJo",
        "outputId": "8462c9c6-f886-440e-c539-4428a4c00d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/teeth.zip\n",
            "  inflating: /content/datasets/data.yaml  \n",
            "   creating: /content/datasets/test/images/\n",
            "  inflating: /content/datasets/test/images/1009.png  \n",
            "  inflating: /content/datasets/test/images/1016.png  \n",
            "  inflating: /content/datasets/test/images/1096.png  \n",
            "  inflating: /content/datasets/test/images/318.png  \n",
            "  inflating: /content/datasets/test/images/354.png  \n",
            "  inflating: /content/datasets/test/images/702.png  \n",
            "  inflating: /content/datasets/test/images/750.png  \n",
            "  inflating: /content/datasets/test/images/783.png  \n",
            "  inflating: /content/datasets/test/images/822.png  \n",
            "  inflating: /content/datasets/test/images/837.png  \n",
            "  inflating: /content/datasets/test/images/855.png  \n",
            "  inflating: /content/datasets/test/images/856.png  \n",
            "  inflating: /content/datasets/test/images/861.png  \n",
            "  inflating: /content/datasets/test/images/913.png  \n",
            "  inflating: /content/datasets/test/images/942.png  \n",
            "   creating: /content/datasets/test/labels/\n",
            "  inflating: /content/datasets/test/labels/1009.txt  \n",
            "  inflating: /content/datasets/test/labels/1016.txt  \n",
            "  inflating: /content/datasets/test/labels/1096.txt  \n",
            "  inflating: /content/datasets/test/labels/318.txt  \n",
            "  inflating: /content/datasets/test/labels/354.txt  \n",
            "  inflating: /content/datasets/test/labels/702.txt  \n",
            "  inflating: /content/datasets/test/labels/750.txt  \n",
            "  inflating: /content/datasets/test/labels/783.txt  \n",
            "  inflating: /content/datasets/test/labels/822.txt  \n",
            "  inflating: /content/datasets/test/labels/837.txt  \n",
            "  inflating: /content/datasets/test/labels/855.txt  \n",
            "  inflating: /content/datasets/test/labels/856.txt  \n",
            "  inflating: /content/datasets/test/labels/861.txt  \n",
            "  inflating: /content/datasets/test/labels/913.txt  \n",
            "  inflating: /content/datasets/test/labels/942.txt  \n",
            "   creating: /content/datasets/train/images/\n",
            "  inflating: /content/datasets/train/images/1018.png  \n",
            "  inflating: /content/datasets/train/images/1026.png  \n",
            "  inflating: /content/datasets/train/images/1033.png  \n",
            "  inflating: /content/datasets/train/images/1042.png  \n",
            "  inflating: /content/datasets/train/images/1058.png  \n",
            "  inflating: /content/datasets/train/images/1080.png  \n",
            "  inflating: /content/datasets/train/images/1083.png  \n",
            "  inflating: /content/datasets/train/images/1088.png  \n",
            "  inflating: /content/datasets/train/images/1091.png  \n",
            "  inflating: /content/datasets/train/images/1092.png  \n",
            "  inflating: /content/datasets/train/images/306.png  \n",
            "  inflating: /content/datasets/train/images/310.png  \n",
            "  inflating: /content/datasets/train/images/347.png  \n",
            "  inflating: /content/datasets/train/images/350.png  \n",
            "  inflating: /content/datasets/train/images/360.png  \n",
            "  inflating: /content/datasets/train/images/367.png  \n",
            "  inflating: /content/datasets/train/images/369.png  \n",
            "  inflating: /content/datasets/train/images/370.png  \n",
            "  inflating: /content/datasets/train/images/372.png  \n",
            "  inflating: /content/datasets/train/images/376.png  \n",
            "  inflating: /content/datasets/train/images/378.png  \n",
            "  inflating: /content/datasets/train/images/383.png  \n",
            "  inflating: /content/datasets/train/images/388.png  \n",
            "  inflating: /content/datasets/train/images/392.png  \n",
            "  inflating: /content/datasets/train/images/395.png  \n",
            "  inflating: /content/datasets/train/images/396.png  \n",
            "  inflating: /content/datasets/train/images/706.png  \n",
            "  inflating: /content/datasets/train/images/708.png  \n",
            "  inflating: /content/datasets/train/images/710.png  \n",
            "  inflating: /content/datasets/train/images/714.png  \n",
            "  inflating: /content/datasets/train/images/715.png  \n",
            "  inflating: /content/datasets/train/images/724.png  \n",
            "  inflating: /content/datasets/train/images/732.png  \n",
            "  inflating: /content/datasets/train/images/736.png  \n",
            "  inflating: /content/datasets/train/images/748.png  \n",
            "  inflating: /content/datasets/train/images/755.png  \n",
            "  inflating: /content/datasets/train/images/758.png  \n",
            "  inflating: /content/datasets/train/images/761.png  \n",
            "  inflating: /content/datasets/train/images/769.png  \n",
            "  inflating: /content/datasets/train/images/777.png  \n",
            "  inflating: /content/datasets/train/images/786.png  \n",
            "  inflating: /content/datasets/train/images/790.png  \n",
            "  inflating: /content/datasets/train/images/793.png  \n",
            "  inflating: /content/datasets/train/images/797.png  \n",
            "  inflating: /content/datasets/train/images/804.png  \n",
            "  inflating: /content/datasets/train/images/810.png  \n",
            "  inflating: /content/datasets/train/images/812.png  \n",
            "  inflating: /content/datasets/train/images/818.png  \n",
            "  inflating: /content/datasets/train/images/819.png  \n",
            "  inflating: /content/datasets/train/images/842.png  \n",
            "  inflating: /content/datasets/train/images/857.png  \n",
            "  inflating: /content/datasets/train/images/858.png  \n",
            "  inflating: /content/datasets/train/images/859.png  \n",
            "  inflating: /content/datasets/train/images/866.png  \n",
            "  inflating: /content/datasets/train/images/867.png  \n",
            "  inflating: /content/datasets/train/images/872.png  \n",
            "  inflating: /content/datasets/train/images/883.png  \n",
            "  inflating: /content/datasets/train/images/886.png  \n",
            "  inflating: /content/datasets/train/images/895.png  \n",
            "  inflating: /content/datasets/train/images/901.png  \n",
            "  inflating: /content/datasets/train/images/925.png  \n",
            "  inflating: /content/datasets/train/images/934.png  \n",
            "  inflating: /content/datasets/train/images/935.png  \n",
            "  inflating: /content/datasets/train/images/939.png  \n",
            "  inflating: /content/datasets/train/images/952.png  \n",
            "  inflating: /content/datasets/train/images/954.png  \n",
            "  inflating: /content/datasets/train/images/963.png  \n",
            "  inflating: /content/datasets/train/images/979.png  \n",
            "  inflating: /content/datasets/train/images/981.png  \n",
            "  inflating: /content/datasets/train/images/996.png  \n",
            "   creating: /content/datasets/train/labels/\n",
            "  inflating: /content/datasets/train/labels/1018.txt  \n",
            "  inflating: /content/datasets/train/labels/1026.txt  \n",
            "  inflating: /content/datasets/train/labels/1033.txt  \n",
            "  inflating: /content/datasets/train/labels/1042.txt  \n",
            "  inflating: /content/datasets/train/labels/1058.txt  \n",
            "  inflating: /content/datasets/train/labels/1080.txt  \n",
            "  inflating: /content/datasets/train/labels/1083.txt  \n",
            "  inflating: /content/datasets/train/labels/1088.txt  \n",
            "  inflating: /content/datasets/train/labels/1091.txt  \n",
            "  inflating: /content/datasets/train/labels/1092.txt  \n",
            "  inflating: /content/datasets/train/labels/306.txt  \n",
            "  inflating: /content/datasets/train/labels/310.txt  \n",
            "  inflating: /content/datasets/train/labels/347.txt  \n",
            "  inflating: /content/datasets/train/labels/350.txt  \n",
            "  inflating: /content/datasets/train/labels/360.txt  \n",
            "  inflating: /content/datasets/train/labels/367.txt  \n",
            "  inflating: /content/datasets/train/labels/369.txt  \n",
            "  inflating: /content/datasets/train/labels/370.txt  \n",
            "  inflating: /content/datasets/train/labels/372.txt  \n",
            "  inflating: /content/datasets/train/labels/376.txt  \n",
            "  inflating: /content/datasets/train/labels/378.txt  \n",
            "  inflating: /content/datasets/train/labels/383.txt  \n",
            "  inflating: /content/datasets/train/labels/388.txt  \n",
            "  inflating: /content/datasets/train/labels/392.txt  \n",
            "  inflating: /content/datasets/train/labels/395.txt  \n",
            "  inflating: /content/datasets/train/labels/396.txt  \n",
            "  inflating: /content/datasets/train/labels/706.txt  \n",
            "  inflating: /content/datasets/train/labels/708.txt  \n",
            "  inflating: /content/datasets/train/labels/710.txt  \n",
            "  inflating: /content/datasets/train/labels/714.txt  \n",
            "  inflating: /content/datasets/train/labels/715.txt  \n",
            "  inflating: /content/datasets/train/labels/724.txt  \n",
            "  inflating: /content/datasets/train/labels/732.txt  \n",
            "  inflating: /content/datasets/train/labels/736.txt  \n",
            "  inflating: /content/datasets/train/labels/748.txt  \n",
            "  inflating: /content/datasets/train/labels/755.txt  \n",
            "  inflating: /content/datasets/train/labels/758.txt  \n",
            "  inflating: /content/datasets/train/labels/761.txt  \n",
            "  inflating: /content/datasets/train/labels/769.txt  \n",
            "  inflating: /content/datasets/train/labels/777.txt  \n",
            "  inflating: /content/datasets/train/labels/786.txt  \n",
            "  inflating: /content/datasets/train/labels/790.txt  \n",
            "  inflating: /content/datasets/train/labels/793.txt  \n",
            "  inflating: /content/datasets/train/labels/797.txt  \n",
            "  inflating: /content/datasets/train/labels/804.txt  \n",
            "  inflating: /content/datasets/train/labels/810.txt  \n",
            "  inflating: /content/datasets/train/labels/812.txt  \n",
            "  inflating: /content/datasets/train/labels/818.txt  \n",
            "  inflating: /content/datasets/train/labels/819.txt  \n",
            "  inflating: /content/datasets/train/labels/842.txt  \n",
            "  inflating: /content/datasets/train/labels/857.txt  \n",
            "  inflating: /content/datasets/train/labels/858.txt  \n",
            "  inflating: /content/datasets/train/labels/859.txt  \n",
            "  inflating: /content/datasets/train/labels/866.txt  \n",
            "  inflating: /content/datasets/train/labels/867.txt  \n",
            "  inflating: /content/datasets/train/labels/872.txt  \n",
            "  inflating: /content/datasets/train/labels/883.txt  \n",
            "  inflating: /content/datasets/train/labels/886.txt  \n",
            "  inflating: /content/datasets/train/labels/895.txt  \n",
            "  inflating: /content/datasets/train/labels/901.txt  \n",
            "  inflating: /content/datasets/train/labels/925.txt  \n",
            "  inflating: /content/datasets/train/labels/934.txt  \n",
            "  inflating: /content/datasets/train/labels/935.txt  \n",
            "  inflating: /content/datasets/train/labels/939.txt  \n",
            "  inflating: /content/datasets/train/labels/952.txt  \n",
            "  inflating: /content/datasets/train/labels/954.txt  \n",
            "  inflating: /content/datasets/train/labels/963.txt  \n",
            "  inflating: /content/datasets/train/labels/979.txt  \n",
            "  inflating: /content/datasets/train/labels/981.txt  \n",
            "  inflating: /content/datasets/train/labels/996.txt  \n",
            "   creating: /content/datasets/valid/images/\n",
            "  inflating: /content/datasets/valid/images/1008.png  \n",
            "  inflating: /content/datasets/valid/images/1050.png  \n",
            "  inflating: /content/datasets/valid/images/1067.png  \n",
            "  inflating: /content/datasets/valid/images/1074.png  \n",
            "  inflating: /content/datasets/valid/images/1090.png  \n",
            "  inflating: /content/datasets/valid/images/323.png  \n",
            "  inflating: /content/datasets/valid/images/365.png  \n",
            "  inflating: /content/datasets/valid/images/717.png  \n",
            "  inflating: /content/datasets/valid/images/740.png  \n",
            "  inflating: /content/datasets/valid/images/759.png  \n",
            "  inflating: /content/datasets/valid/images/778.png  \n",
            "  inflating: /content/datasets/valid/images/784.png  \n",
            "  inflating: /content/datasets/valid/images/814.png  \n",
            "  inflating: /content/datasets/valid/images/875.png  \n",
            "  inflating: /content/datasets/valid/images/885.png  \n",
            "   creating: /content/datasets/valid/labels/\n",
            "  inflating: /content/datasets/valid/labels/1008.txt  \n",
            "  inflating: /content/datasets/valid/labels/1050.txt  \n",
            "  inflating: /content/datasets/valid/labels/1067.txt  \n",
            "  inflating: /content/datasets/valid/labels/1074.txt  \n",
            "  inflating: /content/datasets/valid/labels/1090.txt  \n",
            "  inflating: /content/datasets/valid/labels/323.txt  \n",
            "  inflating: /content/datasets/valid/labels/365.txt  \n",
            "  inflating: /content/datasets/valid/labels/717.txt  \n",
            "  inflating: /content/datasets/valid/labels/740.txt  \n",
            "  inflating: /content/datasets/valid/labels/759.txt  \n",
            "  inflating: /content/datasets/valid/labels/778.txt  \n",
            "  inflating: /content/datasets/valid/labels/784.txt  \n",
            "  inflating: /content/datasets/valid/labels/814.txt  \n",
            "  inflating: /content/datasets/valid/labels/875.txt  \n",
            "  inflating: /content/datasets/valid/labels/885.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jjT5uIHo6l5"
      },
      "source": [
        "# set up environment\n",
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaFNnxLJbq4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd09c778-64f4-4c2b-983b-3a471fdf6b48"
      },
      "source": [
        "!python train.py --img 800 --batch 16 --epochs 20 --data /content/datasets/data.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-23 10:00:34.938669: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-23 10:00:34.938735: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-23 10:00:35.050415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/datasets/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=800, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-313-g712de55a Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 14.1MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 132MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/train/labels... 70 images, 0 backgrounds, 0 corrupt: 100% 70/70 [00:00<00:00, 269.06it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 70/70 [00:04<00:00, 16.74it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/valid/labels... 15 images, 0 backgrounds, 0 corrupt: 100% 15/15 [00:00<00:00, 67.34it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 15/15 [00:03<00:00,  4.89it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.55 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 800 train, 800 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19      5.76G     0.1266     0.1962          0        273        800: 100% 5/5 [00:09<00:00,  1.82s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.36s/it]\n",
            "                   all         15        458    0.00289     0.0284    0.00151   0.000287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/19      5.76G     0.1226     0.2165          0        278        800: 100% 5/5 [00:01<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.04it/s]\n",
            "                   all         15        458    0.00889     0.0873    0.00528      0.001\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/19      5.76G     0.1189      0.227          0        310        800: 100% 5/5 [00:01<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "                   all         15        458     0.0267      0.262     0.0191    0.00398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/19      5.76G     0.1162     0.2463          0        554        800: 100% 5/5 [00:01<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.25s/it]\n",
            "                   all         15        458      0.101      0.225     0.0728      0.015\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/19      5.77G     0.1119     0.2089          0        253        800: 100% 5/5 [00:02<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.250s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.73s/it]\n",
            "                   all         15        458     0.0759      0.386     0.0578     0.0137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/19      5.77G     0.1079     0.2091          0        351        800: 100% 5/5 [00:02<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.13s/it]\n",
            "                   all         15        458      0.129      0.249     0.0853     0.0182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/19      5.77G     0.1032     0.2031          0        285        800: 100% 5/5 [00:01<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.27it/s]\n",
            "                   all         15        458      0.118      0.345     0.0927     0.0196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/19      5.77G    0.09864     0.2028          0        401        800: 100% 5/5 [00:01<00:00,  3.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.77it/s]\n",
            "                   all         15        458      0.108      0.271     0.0879     0.0186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/19      5.77G    0.09369     0.1867          0        353        800: 100% 5/5 [00:01<00:00,  2.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.96it/s]\n",
            "                   all         15        458      0.186      0.382      0.186      0.039\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/19      5.77G    0.09533     0.1668          0        274        800: 100% 5/5 [00:01<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.52it/s]\n",
            "                   all         15        458      0.373      0.566      0.416      0.112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/19      5.77G    0.08975     0.1851          0        463        800: 100% 5/5 [00:02<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.30it/s]\n",
            "                   all         15        458      0.364      0.614      0.462       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/19      5.77G    0.08316     0.1743          0        292        800: 100% 5/5 [00:01<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.31it/s]\n",
            "                   all         15        458      0.316      0.599      0.389      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/19      5.77G    0.08669     0.1802          0        456        800: 100% 5/5 [00:01<00:00,  3.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.02it/s]\n",
            "                   all         15        458      0.368      0.629      0.466      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/19      5.77G    0.07851     0.1786          0        342        800: 100% 5/5 [00:01<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.61it/s]\n",
            "                   all         15        458      0.313      0.618      0.366      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/19      5.77G    0.08139     0.1748          0        400        800: 100% 5/5 [00:01<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.57it/s]\n",
            "                   all         15        458      0.435      0.692      0.529      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/19      5.77G    0.07757     0.1822          0        415        800: 100% 5/5 [00:01<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.36it/s]\n",
            "                   all         15        458      0.415      0.664      0.504      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/19      5.77G     0.0722     0.1808          0        446        800: 100% 5/5 [00:02<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         15        458      0.523      0.725       0.62      0.241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/19      5.77G    0.07208     0.1628          0        284        800: 100% 5/5 [00:01<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.96it/s]\n",
            "                   all         15        458      0.484      0.731      0.595       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/19      5.77G    0.07078     0.1674          0        336        800: 100% 5/5 [00:01<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.93it/s]\n",
            "                   all         15        458      0.527      0.745      0.637      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/19      5.77G    0.06817      0.171          0        403        800: 100% 5/5 [00:01<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.01it/s]\n",
            "                   all         15        458      0.549      0.782      0.672      0.297\n",
            "\n",
            "20 epochs completed in 0.023 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.85it/s]\n",
            "                   all         15        458      0.551      0.782      0.674      0.298\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtmS7_TXFsT3"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWjjiBcic3Vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f49ede4-061f-422b-880f-62e8d5d9dc35"
      },
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 800 --conf 0.7 --source /content/datasets/test/images/1009.png"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/datasets/test/images/1009.png, data=data/coco128.yaml, imgsz=[800, 800], conf_thres=0.7, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-313-g712de55a Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "image 1/1 /content/datasets/test/images/1009.png: 416x800 37 tooths, 51.1ms\n",
            "Speed: 0.7ms pre-process, 51.1ms inference, 654.8ms NMS per image at shape (1, 3, 800, 800)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNn-obvOGITm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b329e1-8f16-49a3-a778-8a63fb47af30"
      },
      "source": [
        "!zip -r yolov5.zip /content/yolov5/runs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/yolov5/runs/ (stored 0%)\n",
            "  adding: content/yolov5/runs/detect/ (stored 0%)\n",
            "  adding: content/yolov5/runs/detect/exp/ (stored 0%)\n",
            "  adding: content/yolov5/runs/detect/exp/1009.png (deflated 22%)\n",
            "  adding: content/yolov5/runs/train/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp/results.png (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/weights/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp/weights/best.pt (deflated 9%)\n",
            "  adding: content/yolov5/runs/train/exp/weights/last.pt (deflated 9%)\n",
            "  adding: content/yolov5/runs/train/exp/labels.jpg (deflated 32%)\n",
            "  adding: content/yolov5/runs/train/exp/confusion_matrix.png (deflated 38%)\n",
            "  adding: content/yolov5/runs/train/exp/R_curve.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/train/exp/train_batch2.jpg (deflated 9%)\n",
            "  adding: content/yolov5/runs/train/exp/opt.yaml (deflated 50%)\n",
            "  adding: content/yolov5/runs/train/exp/F1_curve.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/train/exp/val_batch0_labels.jpg (deflated 9%)\n",
            "  adding: content/yolov5/runs/train/exp/P_curve.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/train/exp/train_batch1.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/train_batch0.jpg (deflated 7%)\n",
            "  adding: content/yolov5/runs/train/exp/results.csv (deflated 82%)\n",
            "  adding: content/yolov5/runs/train/exp/events.out.tfevents.1716458439.7b552658fd09.5151.0 (deflated 39%)\n",
            "  adding: content/yolov5/runs/train/exp/hyp.yaml (deflated 45%)\n",
            "  adding: content/yolov5/runs/train/exp/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/PR_curve.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/train/exp/labels_correlogram.jpg (deflated 39%)\n"
          ]
        }
      ]
    }
  ]
}